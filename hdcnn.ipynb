{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchically Deep Convolutional Neural Network For Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 \n",
    "\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't pre-allocate memory; allocate as-needed\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3 # Only allow a total fraction the GPU memory to be allocated\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/models/'):\n",
    "    os.mkdir('data/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GGN = True\n",
    "\n",
    "# The number of coarse categories\n",
    "coarse_categories = 20\n",
    "\n",
    "# The number of fine categories\n",
    "fine_categories = 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Cifar100 Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X, y_c), (x_test, y_c_test) = cifar100.load_data(label_mode='coarse')\n",
    "# (X, y), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Cham Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"dataset/train_feature.npy\")\n",
    "y = np.load(\"dataset/train_label.npy\")\n",
    "y_c = np.load(\"dataset/train_label_coarse.npy\")\n",
    "\n",
    "x_test = np.load(\"dataset/test_feature.npy\")\n",
    "y_test = np.load(\"dataset/test_label.npy\")\n",
    "y_c_test = np.load(\"dataset/test_label_coarse.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-To-Coarse Mapping**\n",
    "\n",
    "(Ideally, this would be done through spectral clustering as opposed to hard-coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
    "for i in range(coarse_categories):\n",
    "    index = np.where(y_c_test[:,0] == i)[0]\n",
    "    fine_cat = np.unique([y_test[j,0] for j in index])\n",
    "    if len(index) == 0:\n",
    "        print i\n",
    "    for j in fine_cat:\n",
    "        fine2coarse[j,i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = 0; # Clear y_c in interest of saving mem\n",
    "y_c_test=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: One Hot Encoding\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function extends a matrix to one-hot encoding\n",
    "#    \n",
    "#    Parameters:\n",
    "#        y    Array of label values\n",
    "# \n",
    "#    Returns:\n",
    "#        y_new    One hot encoded array of labels\n",
    "################################################################################\n",
    "def one_hot(y):\n",
    "    n_values = np.max(y) + 1\n",
    "    y_new = np.eye(n_values)[y[:,0]]\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2359, 61)\n"
     ]
    }
   ],
   "source": [
    "y=one_hot(y)\n",
    "y_test=one_hot(y_test)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply ZCA Whitening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: ZCA\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function applies ZCA Whitening to the image set\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def zca(x_1, x_2, epsilon=1e-5):\n",
    "        \n",
    "    with tf.name_scope('ZCA'):\n",
    "        \n",
    "        x1 = tf.placeholder(tf.float64, shape=np.shape(x_1), name='placeholder_x1')\n",
    "        x2 = tf.placeholder(tf.float64, shape=np.shape(x_2), name='placeholder_x2')\n",
    "        \n",
    "        flatx = tf.cast(tf.reshape(x1, (-1, np.prod(x_1.shape[-3:])),name=\"reshape_flat\"),tf.float64,name=\"flatx\")\n",
    "        sigma = tf.tensordot(tf.transpose(flatx),flatx, 1,name=\"sigma\") / tf.cast(tf.shape(flatx)[0],tf.float64) ### N-1 or N?\n",
    "        s, u, v = tf.svd(sigma,name=\"svd\")\n",
    "        pc = tf.tensordot(tf.tensordot(u,tf.diag(1. / tf.sqrt(s+epsilon)),1,name=\"inner_dot\"),tf.transpose(u),1, name=\"pc\")\n",
    "        \n",
    "        net1 = tf.tensordot(flatx, pc,1,name=\"whiten1\")\n",
    "        net1 = tf.reshape(net1,np.shape(x_1), name=\"output1\")\n",
    "        \n",
    "        flatx2 = tf.cast(tf.reshape(x2, (-1, np.prod(x_2.shape[-3:])),name=\"reshape_flat2\"),tf.float64,name=\"flatx2\")\n",
    "        net2 = tf.tensordot(flatx2, pc,1,name=\"whiten2\")\n",
    "        net2 = tf.reshape(net2,np.shape(x_2), name=\"output2\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_1,x_2 = sess.run([net1,net2], feed_dict={x1: x_1, x2: x_2})    \n",
    "    return x_1,x_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "time1 = time.time()\n",
    "X,x_test = zca(X,x_test)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - ZCA Whitening: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Training set into Training and Validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=.1, stratify=y, random_state=0)\n",
    "X = 0\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_cifar100_data(X_train, Y_train, X_valid, Y_valid, img_rows, img_cols):\n",
    "    \n",
    "    nb_train_samples = 3000 # 3000 training samples\n",
    "    nb_valid_samples = 100 # 100 validation samples\n",
    "    # Load cifar10 training and validation sets\n",
    "    # (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "#     Y_train = np_utils.to_categorical(Y_train[:], num_classes)\n",
    "#     Y_valid = np_utils.to_categorical(Y_valid[:], num_classes)\n",
    "    Y_train = Y_train[:nb_train_samples]\n",
    "    Y_valid = Y_valid[:nb_valid_samples]\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# only for CIFAR100\n",
    "if GGN:\n",
    "    x_train, y_train, x_val, y_val = resize_cifar100_data(x_train, y_train, x_val, y_val, 224, 224)\n",
    "else:\n",
    "    x_train, y_train, x_val, y_val = resize_cifar100_data(x_train, y_train, x_val, y_val, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flip, pad and randomly crop each photo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: Preprocess Img\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function pads images by 4 pixels, randomly crops them, then\n",
    "#        randomly flips them\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def preprocess_img(X,y):\n",
    "        \n",
    "    with tf.name_scope('Preproc'):\n",
    "        \n",
    "        images = tf.placeholder(tf.float64, shape=np.shape(X))\n",
    "        labels = tf.placeholder(tf.float64, shape=np.shape(y))\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.flip_left_right(img), images)\n",
    "        net = tf.map_fn(lambda img: tf.image.rot90(img), net)\n",
    "        net = tf.image.resize_image_with_crop_or_pad(net,40,40)\n",
    "        net = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net)\n",
    "\n",
    "        net1 = tf.image.resize_image_with_crop_or_pad(images,40,40)\n",
    "        net1 = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net1)\n",
    "        \n",
    "        net = tf.concat([net, net1],0)\n",
    "        net = tf.random_shuffle(net, seed=0)\n",
    "        net_labels = tf.concat([labels, labels],0)\n",
    "        net_labels = tf.random_shuffle(net_labels,seed=0)\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.random_flip_up_down(img), net)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_t,y_t = sess.run([net,net_labels], feed_dict={images: X, labels: y})    \n",
    "    return x_t,y_t\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "time1 = time.time()\n",
    "x_train,y_train = preprocess_img(x_train,y_train)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - Img Preprocessing: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# in_layer = Input(shape=(32, 32, 3), dtype='float32', name='main_input')\n",
    "\n",
    "# net = Conv2D(384, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(384, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(384, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.2)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(640, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.3)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(768, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.4)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(896, 3, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.5)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.6)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "# net = Flatten()(net)\n",
    "# net = Dense(1152, activation='elu')(net)\n",
    "# net = Dense(100, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_m = precision(y_true, y_pred)\n",
    "    recall_m = recall(y_true, y_pred)\n",
    "    return 2*((precision_m*recall_m)/(precision_m+recall_m+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GGN: \n",
    "    # Inception v1\n",
    "    from inception_v1 import InceptionV1\n",
    "    in_layer, net, model = InceptionV1(weights=None,classes=fine_categories) # classes = sum of all fine classes\n",
    "else:\n",
    "    # NiN\n",
    "    model = Model(inputs=in_layer,outputs=net)\n",
    "    \n",
    "sgd_coarse = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy', f1_score, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('data/models/model_coarse'+str(30)+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training history visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_histo_vis(history,title):\n",
    "        \n",
    "#     acc = [hist.history['f1_score'] for hist in history]\n",
    "#     val_acc = [hist.history['val_f1_score'] for hist in history]\n",
    "#     loss = [hist.history['loss'] for hist in history]\n",
    "#     val_loss = [hist.history['val_loss'] for hist in history]\n",
    "    acc = history.history['f1_score']\n",
    "    val_acc = history.history['val_f1_score']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training F1_score')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation F1_score')\n",
    "    plt.title('Training and validation F1_score')\n",
    "    plt.ylabel('F1_score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(title+\"_f1_score.png\",bbox_inches='tight')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(title+\"_loss.png\",bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_his(history_model, history_path):\n",
    "    # Get the dictionary containing each metric and the loss for each epoch\n",
    "    history_dict = history_model.history\n",
    "    # Save it under the form of a json file\n",
    "    json.dump(history_dict, open(history_path, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = kr.callbacks.TensorBoard(log_dir='./data/graph/elu_drop/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# Source: https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "# Checkpoint Best Neural Network Model Only\n",
    "# filepath=\"weights.best.hdf5\"\n",
    "# Checkpoint Neural Network Model Improvements\n",
    "filepath=\"data/models/weights-improvement-{epoch:02d}-{val_f1_score:.4f}.hdf5\"\n",
    "checkpointer = kr.callbacks.ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "callbacks_list = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.06990, saving model to data/models/weights-improvement-01-0.0699.hdf5\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.06990 to 0.12973, saving model to data/models/weights-improvement-02-0.1297.hdf5\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.12973 to 0.30626, saving model to data/models/weights-improvement-03-0.3063.hdf5\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.30626 to 0.47598, saving model to data/models/weights-improvement-04-0.4760.hdf5\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.47598\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.47598 to 0.48742, saving model to data/models/weights-improvement-06-0.4874.hdf5\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.48742 to 0.60916, saving model to data/models/weights-improvement-07-0.6092.hdf5\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.60916\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.60916\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.60916\n",
      "\n",
      "Epoch 00011: val_f1_score improved from 0.60916 to 0.73959, saving model to data/models/weights-improvement-11-0.7396.hdf5\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.73959\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.73959 to 0.80137, saving model to data/models/weights-improvement-13-0.8014.hdf5\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.80137\n",
      "\n",
      "Epoch 00026: val_f1_score improved from 0.80137 to 0.82841, saving model to data/models/weights-improvement-26-0.8284.hdf5\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.82841\n",
      "\n",
      "Epoch 00028: val_f1_score improved from 0.82841 to 0.85037, saving model to data/models/weights-improvement-28-0.8504.hdf5\n",
      "\n",
      "Epoch 00029: val_f1_score improved from 0.85037 to 0.86525, saving model to data/models/weights-improvement-29-0.8653.hdf5\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.86525\n",
      "\n",
      "Epoch 00031: val_f1_score improved from 0.86525 to 0.87450, saving model to data/models/weights-improvement-31-0.8745.hdf5\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.87450\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.87450\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.87450\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.87450\n",
      "\n",
      "Epoch 00036: val_f1_score improved from 0.87450 to 0.89011, saving model to data/models/weights-improvement-36-0.8901.hdf5\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.89011\n",
      "\n",
      "Epoch 00048: val_f1_score improved from 0.89011 to 0.90484, saving model to data/models/weights-improvement-48-0.9048.hdf5\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.90484\n",
      "\n",
      "Epoch 00067: val_f1_score improved from 0.90484 to 0.90989, saving model to data/models/weights-improvement-67-0.9099.hdf5\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.90989\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.90989\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.90989\n",
      "\n",
      "Epoch 00071: val_f1_score improved from 0.90989 to 0.91299, saving model to data/models/weights-improvement-71-0.9130.hdf5\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.91299\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.91299\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.91299\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.91299\n",
      "\n",
      "Epoch 00076: val_f1_score did not improve from 0.91299\n",
      "\n",
      "Epoch 00077: val_f1_score improved from 0.91299 to 0.91610, saving model to data/models/weights-improvement-77-0.9161.hdf5\n",
      "\n",
      "Epoch 00078: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00079: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00080: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00081: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00082: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00083: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00084: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00085: val_f1_score did not improve from 0.91610\n",
      "\n",
      "Epoch 00086: val_f1_score improved from 0.91610 to 0.91723, saving model to data/models/weights-improvement-86-0.9172.hdf5\n",
      "\n",
      "Epoch 00087: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00088: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00089: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00090: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00091: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00092: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00093: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00094: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00095: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00096: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00097: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00098: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00099: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00100: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00101: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00102: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00103: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00104: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00105: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00106: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00107: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00108: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00109: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00110: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00111: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00112: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00113: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00114: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00115: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00116: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00117: val_f1_score did not improve from 0.91723\n",
      "\n",
      "Epoch 00118: val_f1_score improved from 0.91723 to 0.91893, saving model to data/models/weights-improvement-118-0.9189.hdf5\n",
      "\n",
      "Epoch 00119: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00120: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00121: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00122: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00123: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00124: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00125: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00126: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00127: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00128: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00129: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00130: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00131: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00132: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00133: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00134: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00135: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00136: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00137: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00138: val_f1_score did not improve from 0.91893\n",
      "\n",
      "Epoch 00139: val_f1_score improved from 0.91893 to 0.92345, saving model to data/models/weights-improvement-139-0.9234.hdf5\n",
      "\n",
      "Epoch 00140: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00141: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00142: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00143: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00144: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00145: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00146: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00147: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00148: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00149: val_f1_score did not improve from 0.92345\n",
      "\n",
      "Epoch 00150: val_f1_score improved from 0.92345 to 0.92542, saving model to data/models/weights-improvement-150-0.9254.hdf5\n",
      "\n",
      "Epoch 00151: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00152: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00153: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00154: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00155: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00156: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00157: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00158: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00159: val_f1_score did not improve from 0.92542\n",
      "\n",
      "Epoch 00160: val_f1_score improved from 0.92542 to 0.92740, saving model to data/models/weights-improvement-160-0.9274.hdf5\n",
      "\n",
      "Epoch 00161: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00162: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00163: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00164: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00165: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00166: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00167: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00168: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00169: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00170: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00171: val_f1_score did not improve from 0.92740\n",
      "\n",
      "Epoch 00172: val_f1_score improved from 0.92740 to 0.93814, saving model to data/models/weights-improvement-172-0.9381.hdf5\n",
      "\n",
      "Epoch 00173: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00174: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00175: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00176: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00177: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00178: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00179: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00180: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00181: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00182: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00183: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00184: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00185: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00186: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00187: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00188: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00189: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00190: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00191: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00192: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00193: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00194: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00195: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00196: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00197: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00198: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00199: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00200: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00201: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00202: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00203: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00204: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00205: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00206: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00207: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00208: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00209: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00210: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00211: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00212: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00213: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00214: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00215: val_f1_score did not improve from 0.93814\n",
      "\n",
      "Epoch 00216: val_f1_score improved from 0.93814 to 0.94068, saving model to data/models/weights-improvement-216-0.9407.hdf5\n",
      "\n",
      "Epoch 00217: val_f1_score improved from 0.94068 to 0.94492, saving model to data/models/weights-improvement-217-0.9449.hdf5\n",
      "\n",
      "Epoch 00218: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00219: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00220: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00221: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00222: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00223: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00224: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00225: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00226: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00227: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00228: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00229: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00230: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00231: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00232: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00233: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00234: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00235: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00236: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00237: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00238: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00239: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00240: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00241: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00242: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00243: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00244: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00245: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00246: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00247: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00248: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00249: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00250: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00251: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00252: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00253: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00254: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00255: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00256: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00257: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00258: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00259: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00260: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00261: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00262: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00263: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00264: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00265: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00266: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00267: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00268: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00269: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00270: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00271: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00272: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00273: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00274: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00275: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00276: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00277: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00278: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00279: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00280: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00281: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00282: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00283: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00284: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00285: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00286: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00287: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00288: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00289: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00290: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00291: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00292: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00293: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00294: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00295: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00296: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00297: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00298: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00299: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00300: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00301: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00302: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00303: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00304: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00305: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00306: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00307: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00308: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00309: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00310: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00311: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00312: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00313: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00314: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00315: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00316: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00317: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00318: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00319: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00320: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00321: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00322: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00323: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00324: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00325: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00326: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00327: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00328: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00329: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00330: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00331: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00332: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00333: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00334: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00335: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00336: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00337: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00338: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00339: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00340: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00341: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00342: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00343: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00344: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00345: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00346: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00347: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00348: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00349: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00350: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00351: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00352: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00353: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00354: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00355: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00356: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00357: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00358: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00359: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00360: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00361: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00362: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00363: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00364: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00365: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00366: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00367: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00368: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00369: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00370: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00371: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00372: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00373: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00374: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00375: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00376: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00377: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00378: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00379: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00380: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00381: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00382: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00383: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00384: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00385: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00386: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00387: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00388: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00389: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00390: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00391: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00392: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00393: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00394: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00395: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00396: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00397: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00398: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00399: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00400: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00401: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00402: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00403: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00404: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00405: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00406: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00407: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00408: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00409: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00410: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00411: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00412: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00413: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00414: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00415: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00416: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00417: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00418: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00419: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00420: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00421: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00422: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00423: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00424: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00425: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00426: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00427: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00428: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00429: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00430: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00431: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00432: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00433: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00434: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00435: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00436: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00437: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00438: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00439: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00440: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00441: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00442: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00443: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00444: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00445: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00446: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00447: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00448: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00449: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00450: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00451: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00452: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00453: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00454: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00455: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00456: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00457: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00458: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00459: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00460: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00461: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00462: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00463: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00464: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00465: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00466: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00467: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00468: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00469: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00470: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00471: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00472: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00473: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00474: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00475: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00476: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00477: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00478: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00479: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00480: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00481: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00482: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00483: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00484: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00485: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00486: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00487: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00488: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00489: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00490: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00491: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00492: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00493: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00494: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00495: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00496: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00497: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00498: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00499: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00500: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00501: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00502: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00503: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00504: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00505: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00506: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00507: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00508: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00509: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00510: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00511: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00512: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00513: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00514: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00515: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00516: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00517: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00518: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00519: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00520: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00521: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00522: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00523: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00524: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00525: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00526: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00527: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00528: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00529: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00530: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00531: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00532: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00533: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00534: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00535: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00536: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00537: val_f1_score improved from 0.94492 to 0.94492, saving model to data/models/weights-improvement-537-0.9449.hdf5\n",
      "\n",
      "Epoch 00538: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00539: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00540: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00541: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00542: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00543: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00544: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00545: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00546: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00547: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00548: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00549: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00550: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00551: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00552: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00553: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00554: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00555: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00556: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00557: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00558: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00559: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00560: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00561: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00562: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00563: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00564: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00565: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00566: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00567: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00568: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00569: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00570: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00571: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00572: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00573: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00574: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00575: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00576: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00577: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00578: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00579: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00580: val_f1_score did not improve from 0.94492\n",
      "\n",
      "Epoch 00581: val_f1_score improved from 0.94492 to 0.94689, saving model to data/models/weights-improvement-581-0.9469.hdf5\n",
      "\n",
      "Epoch 00582: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00583: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00584: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00585: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00586: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00587: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00588: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00589: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00590: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00591: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00592: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00593: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00594: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00595: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00596: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00597: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00598: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00599: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00600: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00601: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00602: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00603: val_f1_score improved from 0.94689 to 0.94689, saving model to data/models/weights-improvement-603-0.9469.hdf5\n",
      "\n",
      "Epoch 00604: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00605: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00606: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00607: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00608: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00609: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00610: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00611: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00612: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00613: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00614: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00615: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00616: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00617: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00618: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00619: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00620: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00621: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00622: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00623: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00624: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00625: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00626: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00627: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00628: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00629: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00630: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00631: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00632: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00633: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00634: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00635: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00636: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00637: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00638: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00639: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00640: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00641: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00642: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00643: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00644: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00645: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00646: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00647: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00648: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00649: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00650: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00651: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00652: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00653: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00654: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00655: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00656: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00657: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00658: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00659: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00660: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00661: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00662: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00663: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00664: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00665: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00666: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00667: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00668: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00669: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00670: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00671: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00672: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00673: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00674: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00675: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00676: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00677: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00678: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00679: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00680: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00681: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00682: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00683: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00684: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00685: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00686: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00687: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00688: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00689: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00690: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00691: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00692: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00693: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00694: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00695: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00696: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00697: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00698: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00699: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00700: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00701: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00702: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00703: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00704: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00705: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00706: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00707: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00708: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00709: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00710: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00711: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00712: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00713: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00714: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00715: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00716: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00717: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00718: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00719: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00720: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00721: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00722: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00723: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00724: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00725: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00726: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00727: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00728: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00729: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00730: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00731: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00732: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00733: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00734: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00735: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00736: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00737: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00738: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00739: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00740: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00741: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00742: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00743: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00744: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00745: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00746: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00747: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00748: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00749: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00750: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00751: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00752: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00753: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00754: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00755: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00756: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00757: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00758: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00759: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00760: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00761: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00762: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00763: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00764: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00765: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00766: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00767: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00768: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00769: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00770: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00771: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00772: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00773: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00774: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00775: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00776: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00777: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00778: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00779: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00780: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00781: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00782: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00783: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00784: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00785: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00786: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00787: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00788: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00789: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00790: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00791: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00792: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00793: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00794: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00795: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00796: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00797: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00798: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00799: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00800: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00801: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00802: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00803: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00804: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00805: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00806: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00807: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00808: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00809: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00810: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00811: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00812: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00813: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00814: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00815: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00816: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00817: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00818: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00819: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00820: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00821: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00822: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00823: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00824: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00825: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00826: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00827: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00828: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00829: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00830: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00831: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00832: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00833: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00834: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00835: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00836: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00837: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00838: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00839: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00840: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00841: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00842: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00843: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00844: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00845: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00846: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00847: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00848: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00849: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00850: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00851: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00852: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00853: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00854: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00855: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00856: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00857: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00858: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00859: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00860: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00861: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00862: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00863: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00864: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00865: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00866: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00867: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00868: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00869: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00870: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00871: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00872: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00873: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00874: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00875: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00876: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00877: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00878: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00879: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00880: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00881: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00882: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00883: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00884: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00885: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00886: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00887: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00888: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00889: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00890: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00891: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00892: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00893: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00894: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00895: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00896: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00897: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00898: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00899: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00900: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00901: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00902: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00903: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00904: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00905: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00906: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00907: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00908: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00909: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00910: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00911: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00912: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00913: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00914: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00915: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00916: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00917: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00918: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00919: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00920: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00921: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00922: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00923: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00924: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00925: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00926: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00927: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00928: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00929: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00930: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00931: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00932: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00933: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00934: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00935: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00936: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00937: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00938: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00939: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00940: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00941: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00942: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00943: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00944: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00945: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00946: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00947: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00948: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00949: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00950: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00951: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00952: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00953: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00954: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00955: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00956: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00957: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00958: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00959: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00960: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00961: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00962: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00963: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00964: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00965: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00966: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00967: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00968: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00969: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00970: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00971: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00972: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00973: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00974: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00975: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00976: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00977: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00978: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00979: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00980: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00981: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00982: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00983: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00984: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00985: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00986: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00987: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00988: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00989: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00990: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00991: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00992: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00993: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00994: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00995: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00996: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00997: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00998: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00999: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 01000: val_f1_score did not improve from 0.94689\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_data=(x_val, y_val), callbacks=[tbCallBack, checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_histo_vis(history, \"history/Single_cls\")\n",
    "save_his(history, \"history/single_cls.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_fine = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'main_input')\n",
      "(1, 'Conv2d_1a_7x7_conv')\n",
      "(2, 'Conv2d_1a_7x7_bn')\n",
      "(3, 'Conv2d_1a_7x7_act')\n",
      "(4, 'MaxPool_2a_3x3')\n",
      "(5, 'Conv2d_2b_1x1_conv')\n",
      "(6, 'Conv2d_2b_1x1_bn')\n",
      "(7, 'Conv2d_2b_1x1_act')\n",
      "(8, 'Conv2d_2c_3x3_conv')\n",
      "(9, 'Conv2d_2c_3x3_bn')\n",
      "(10, 'Conv2d_2c_3x3_act')\n",
      "(11, 'MaxPool_3a_3x3')\n",
      "(12, 'Mixed_3b_Branch_1_a_1x1_conv')\n",
      "(13, 'Mixed_3b_Branch_2_a_1x1_conv')\n",
      "(14, 'Mixed_3b_Branch_1_a_1x1_bn')\n",
      "(15, 'Mixed_3b_Branch_2_a_1x1_bn')\n",
      "(16, 'Mixed_3b_Branch_1_a_1x1_act')\n",
      "(17, 'Mixed_3b_Branch_2_a_1x1_act')\n",
      "(18, 'Mixed_3b_Branch_3_a_max')\n",
      "(19, 'Mixed_3b_Branch_0_a_1x1_conv')\n",
      "(20, 'Mixed_3b_Branch_1_b_3x3_conv')\n",
      "(21, 'Mixed_3b_Branch_2_b_3x3_conv')\n",
      "(22, 'Mixed_3b_Branch_3_b_1x1_conv')\n",
      "(23, 'Mixed_3b_Branch_0_a_1x1_bn')\n",
      "(24, 'Mixed_3b_Branch_1_b_3x3_bn')\n",
      "(25, 'Mixed_3b_Branch_2_b_3x3_bn')\n",
      "(26, 'Mixed_3b_Branch_3_b_1x1_bn')\n",
      "(27, 'Mixed_3b_Branch_0_a_1x1_act')\n",
      "(28, 'Mixed_3b_Branch_1_b_3x3_act')\n",
      "(29, 'Mixed_3b_Branch_2_b_3x3_act')\n",
      "(30, 'Mixed_3b_Branch_3_b_1x1_act')\n",
      "(31, 'Mixed_3b_Concatenated')\n",
      "(32, 'Mixed_3c_Branch_1_a_1x1_conv')\n",
      "(33, 'Mixed_3c_Branch_2_a_1x1_conv')\n",
      "(34, 'Mixed_3c_Branch_1_a_1x1_bn')\n",
      "(35, 'Mixed_3c_Branch_2_a_1x1_bn')\n",
      "(36, 'Mixed_3c_Branch_1_a_1x1_act')\n",
      "(37, 'Mixed_3c_Branch_2_a_1x1_act')\n",
      "(38, 'Mixed_3c_Branch_3_a_max')\n",
      "(39, 'Mixed_3c_Branch_0_a_1x1_conv')\n",
      "(40, 'Mixed_3c_Branch_1_b_3x3_conv')\n",
      "(41, 'Mixed_3c_Branch_2_b_3x3_conv')\n",
      "(42, 'Mixed_3c_Branch_3_b_1x1_conv')\n",
      "(43, 'Mixed_3c_Branch_0_a_1x1_bn')\n",
      "(44, 'Mixed_3c_Branch_1_b_3x3_bn')\n",
      "(45, 'Mixed_3c_Branch_2_b_3x3_bn')\n",
      "(46, 'Mixed_3c_Branch_3_b_1x1_bn')\n",
      "(47, 'Mixed_3c_Branch_0_a_1x1_act')\n",
      "(48, 'Mixed_3c_Branch_1_b_3x3_act')\n",
      "(49, 'Mixed_3c_Branch_2_b_3x3_act')\n",
      "(50, 'Mixed_3c_Branch_3_b_1x1_act')\n",
      "(51, 'Mixed_3c_Concatenated')\n",
      "(52, 'MaxPool_4a_3x3')\n",
      "(53, 'Mixed_4b_Branch_1_a_1x1_conv')\n",
      "(54, 'Mixed_4b_Branch_2_a_1x1_conv')\n",
      "(55, 'Mixed_4b_Branch_1_a_1x1_bn')\n",
      "(56, 'Mixed_4b_Branch_2_a_1x1_bn')\n",
      "(57, 'Mixed_4b_Branch_1_a_1x1_act')\n",
      "(58, 'Mixed_4b_Branch_2_a_1x1_act')\n",
      "(59, 'Mixed_4b_Branch_3_a_max')\n",
      "(60, 'Mixed_4b_Branch_0_a_1x1_conv')\n",
      "(61, 'Mixed_4b_Branch_1_b_3x3_conv')\n",
      "(62, 'Mixed_4b_Branch_2_b_3x3_conv')\n",
      "(63, 'Mixed_4b_Branch_3_b_1x1_conv')\n",
      "(64, 'Mixed_4b_Branch_0_a_1x1_bn')\n",
      "(65, 'Mixed_4b_Branch_1_b_3x3_bn')\n",
      "(66, 'Mixed_4b_Branch_2_b_3x3_bn')\n",
      "(67, 'Mixed_4b_Branch_3_b_1x1_bn')\n",
      "(68, 'Mixed_4b_Branch_0_a_1x1_act')\n",
      "(69, 'Mixed_4b_Branch_1_b_3x3_act')\n",
      "(70, 'Mixed_4b_Branch_2_b_3x3_act')\n",
      "(71, 'Mixed_4b_Branch_3_b_1x1_act')\n",
      "(72, 'Mixed_4b_Concatenated')\n",
      "(73, 'Mixed_4c_Branch_1_a_1x1_conv')\n",
      "(74, 'Mixed_4c_Branch_2_a_1x1_conv')\n",
      "(75, 'Mixed_4c_Branch_1_a_1x1_bn')\n",
      "(76, 'Mixed_4c_Branch_2_a_1x1_bn')\n",
      "(77, 'Mixed_4c_Branch_1_a_1x1_act')\n",
      "(78, 'Mixed_4c_Branch_2_a_1x1_act')\n",
      "(79, 'Mixed_4c_Branch_3_a_max')\n",
      "(80, 'Mixed_4c_Branch_0_a_1x1_conv')\n",
      "(81, 'Mixed_4c_Branch_1_b_3x3_conv')\n",
      "(82, 'Mixed_4c_Branch_2_b_3x3_conv')\n",
      "(83, 'Mixed_4c_Branch_3_b_1x1_conv')\n",
      "(84, 'Mixed_4c_Branch_0_a_1x1_bn')\n",
      "(85, 'Mixed_4c_Branch_1_b_3x3_bn')\n",
      "(86, 'Mixed_4c_Branch_2_b_3x3_bn')\n",
      "(87, 'Mixed_4c_Branch_3_b_1x1_bn')\n",
      "(88, 'Mixed_4c_Branch_0_a_1x1_act')\n",
      "(89, 'Mixed_4c_Branch_1_b_3x3_act')\n",
      "(90, 'Mixed_4c_Branch_2_b_3x3_act')\n",
      "(91, 'Mixed_4c_Branch_3_b_1x1_act')\n",
      "(92, 'Mixed_4c_Concatenated')\n",
      "(93, 'Mixed_4d_Branch_1_a_1x1_conv')\n",
      "(94, 'Mixed_4d_Branch_2_a_1x1_conv')\n",
      "(95, 'Mixed_4d_Branch_1_a_1x1_bn')\n",
      "(96, 'Mixed_4d_Branch_2_a_1x1_bn')\n",
      "(97, 'Mixed_4d_Branch_1_a_1x1_act')\n",
      "(98, 'Mixed_4d_Branch_2_a_1x1_act')\n",
      "(99, 'Mixed_4d_Branch_3_a_max')\n",
      "(100, 'Mixed_4d_Branch_0_a_1x1_conv')\n",
      "(101, 'Mixed_4d_Branch_1_b_3x3_conv')\n",
      "(102, 'Mixed_4d_Branch_2_b_3x3_conv')\n",
      "(103, 'Mixed_4d_Branch_3_b_1x1_conv')\n",
      "(104, 'Mixed_4d_Branch_0_a_1x1_bn')\n",
      "(105, 'Mixed_4d_Branch_1_b_3x3_bn')\n",
      "(106, 'Mixed_4d_Branch_2_b_3x3_bn')\n",
      "(107, 'Mixed_4d_Branch_3_b_1x1_bn')\n",
      "(108, 'Mixed_4d_Branch_0_a_1x1_act')\n",
      "(109, 'Mixed_4d_Branch_1_b_3x3_act')\n",
      "(110, 'Mixed_4d_Branch_2_b_3x3_act')\n",
      "(111, 'Mixed_4d_Branch_3_b_1x1_act')\n",
      "(112, 'Mixed_4d_Concatenated')\n",
      "(113, 'Mixed_4e_Branch_1_a_1x1_conv')\n",
      "(114, 'Mixed_4e_Branch_2_a_1x1_conv')\n",
      "(115, 'Mixed_4e_Branch_1_a_1x1_bn')\n",
      "(116, 'Mixed_4e_Branch_2_a_1x1_bn')\n",
      "(117, 'Mixed_4e_Branch_1_a_1x1_act')\n",
      "(118, 'Mixed_4e_Branch_2_a_1x1_act')\n",
      "(119, 'Mixed_4e_Branch_3_a_max')\n",
      "(120, 'Mixed_4e_Branch_0_a_1x1_conv')\n",
      "(121, 'Mixed_4e_Branch_1_b_3x3_conv')\n",
      "(122, 'Mixed_4e_Branch_2_b_3x3_conv')\n",
      "(123, 'Mixed_4e_Branch_3_b_1x1_conv')\n",
      "(124, 'Mixed_4e_Branch_0_a_1x1_bn')\n",
      "(125, 'Mixed_4e_Branch_1_b_3x3_bn')\n",
      "(126, 'Mixed_4e_Branch_2_b_3x3_bn')\n",
      "(127, 'Mixed_4e_Branch_3_b_1x1_bn')\n",
      "(128, 'Mixed_4e_Branch_0_a_1x1_act')\n",
      "(129, 'Mixed_4e_Branch_1_b_3x3_act')\n",
      "(130, 'Mixed_4e_Branch_2_b_3x3_act')\n",
      "(131, 'Mixed_4e_Branch_3_b_1x1_act')\n",
      "(132, 'Mixed_4e_Concatenated')\n",
      "(133, 'Mixed_4f_Branch_1_a_1x1_conv')\n",
      "(134, 'Mixed_4f_Branch_2_a_1x1_conv')\n",
      "(135, 'Mixed_4f_Branch_1_a_1x1_bn')\n",
      "(136, 'Mixed_4f_Branch_2_a_1x1_bn')\n",
      "(137, 'Mixed_4f_Branch_1_a_1x1_act')\n",
      "(138, 'Mixed_4f_Branch_2_a_1x1_act')\n",
      "(139, 'Mixed_4f_Branch_3_a_max')\n",
      "(140, 'Mixed_4f_Branch_0_a_1x1_conv')\n",
      "(141, 'Mixed_4f_Branch_1_b_3x3_conv')\n",
      "(142, 'Mixed_4f_Branch_2_b_3x3_conv')\n",
      "(143, 'Mixed_4f_Branch_3_b_1x1_conv')\n",
      "(144, 'Mixed_4f_Branch_0_a_1x1_bn')\n",
      "(145, 'Mixed_4f_Branch_1_b_3x3_bn')\n",
      "(146, 'Mixed_4f_Branch_2_b_3x3_bn')\n",
      "(147, 'Mixed_4f_Branch_3_b_1x1_bn')\n",
      "(148, 'Mixed_4f_Branch_0_a_1x1_act')\n",
      "(149, 'Mixed_4f_Branch_1_b_3x3_act')\n",
      "(150, 'Mixed_4f_Branch_2_b_3x3_act')\n",
      "(151, 'Mixed_4f_Branch_3_b_1x1_act')\n",
      "(152, 'Mixed_4f_Concatenated')\n",
      "(153, 'MaxPool_5a_2x2')\n",
      "(154, 'Mixed_5b_Branch_1_a_1x1_conv')\n",
      "(155, 'Mixed_5b_Branch_2_a_1x1_conv')\n",
      "(156, 'Mixed_5b_Branch_1_a_1x1_bn')\n",
      "(157, 'Mixed_5b_Branch_2_a_1x1_bn')\n",
      "(158, 'Mixed_5b_Branch_1_a_1x1_act')\n",
      "(159, 'Mixed_5b_Branch_2_a_1x1_act')\n",
      "(160, 'Mixed_5b_Branch_3_a_max')\n",
      "(161, 'Mixed_5b_Branch_0_a_1x1_conv')\n",
      "(162, 'Mixed_5b_Branch_1_b_3x3_conv')\n",
      "(163, 'Mixed_5b_Branch_2_b_3x3_conv')\n",
      "(164, 'Mixed_5b_Branch_3_b_1x1_conv')\n",
      "(165, 'Mixed_5b_Branch_0_a_1x1_bn')\n",
      "(166, 'Mixed_5b_Branch_1_b_3x3_bn')\n",
      "(167, 'Mixed_5b_Branch_2_b_3x3_bn')\n",
      "(168, 'Mixed_5b_Branch_3_b_1x1_bn')\n",
      "(169, 'Mixed_5b_Branch_0_a_1x1_act')\n",
      "(170, 'Mixed_5b_Branch_1_b_3x3_act')\n",
      "(171, 'Mixed_5b_Branch_2_b_3x3_act')\n",
      "(172, 'Mixed_5b_Branch_3_b_1x1_act')\n",
      "(173, 'Mixed_5b_Concatenated')\n",
      "(174, 'Mixed_5c_Branch_1_a_1x1_conv')\n",
      "(175, 'Mixed_5c_Branch_2_a_1x1_conv')\n",
      "(176, 'Mixed_5c_Branch_1_a_1x1_bn')\n",
      "(177, 'Mixed_5c_Branch_2_a_1x1_bn')\n",
      "(178, 'Mixed_5c_Branch_1_a_1x1_act')\n",
      "(179, 'Mixed_5c_Branch_2_a_1x1_act')\n",
      "(180, 'Mixed_5c_Branch_3_a_max')\n",
      "(181, 'Mixed_5c_Branch_0_a_1x1_conv')\n",
      "(182, 'Mixed_5c_Branch_1_b_3x3_conv')\n",
      "(183, 'Mixed_5c_Branch_2_b_3x3_conv')\n",
      "(184, 'Mixed_5c_Branch_3_b_1x1_conv')\n",
      "(185, 'Mixed_5c_Branch_0_a_1x1_bn')\n",
      "(186, 'Mixed_5c_Branch_1_b_3x3_bn')\n",
      "(187, 'Mixed_5c_Branch_2_b_3x3_bn')\n",
      "(188, 'Mixed_5c_Branch_3_b_1x1_bn')\n",
      "(189, 'Mixed_5c_Branch_0_a_1x1_act')\n",
      "(190, 'Mixed_5c_Branch_1_b_3x3_act')\n",
      "(191, 'Mixed_5c_Branch_2_b_3x3_act')\n",
      "(192, 'Mixed_5c_Branch_3_b_1x1_act')\n",
      "(193, 'Mixed_5c_Concatenated')\n",
      "(194, 'average_pooling2d_1')\n",
      "(195, 'conv2d_1')\n",
      "(196, 'conv2d_2')\n",
      "(197, 'dropout_1')\n",
      "(198, 'max_pooling2d_1')\n",
      "(199, 'flatten_1')\n",
      "(200, 'dense_1')\n",
      "(201, 'dense_2')\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get weights and biases of all layers\n",
    "#for layer in model.layers: print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will freeze all layers\n",
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Coarse Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c = np.dot(y_train,fine2coarse)\n",
    "y_val_c = np.dot(y_val,fine2coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GGN:\n",
    "    # Inception\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='relu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='relu')(net)\n",
    "else:\n",
    "    # NiN\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='relu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='relu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='relu')(net)\n",
    "out_coarse = Dense(20, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model_c.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy', f1_score, precision, recall])\n",
    "\n",
    "# model.load_weights('data/models/model_coarse'+str(10)+'.h5')\n",
    "\n",
    "# for i in range(len(model_c.layers)-1):\n",
    "#     model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('data/models/model_coarse'+str(10)+'.h5')\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00076: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00077: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00078: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00079: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00080: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00081: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00082: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00083: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00084: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00085: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00086: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00087: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00088: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00089: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00090: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00091: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00092: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00093: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00094: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00095: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00096: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00097: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00098: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00099: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00100: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00101: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00102: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00103: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00104: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00105: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00106: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00107: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00108: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00109: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00110: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00111: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00112: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00113: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00114: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00115: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00116: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00117: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00118: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00119: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00120: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00121: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00122: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00123: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00124: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00125: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00126: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00127: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00128: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00129: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00130: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00131: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00132: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00133: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00134: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00135: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00136: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00137: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00138: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00139: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00140: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00141: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00142: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00143: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00144: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00145: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00146: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00147: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00148: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00149: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00150: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00151: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00152: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00153: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00154: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00155: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00156: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00157: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00158: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00159: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00160: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00161: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00162: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00163: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00164: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00165: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00166: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00167: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00168: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00169: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00170: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00171: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00172: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00173: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00174: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00175: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00176: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00177: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00178: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00179: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00180: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00181: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00182: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00183: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00184: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00185: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00186: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00187: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00188: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00189: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00190: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00191: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00192: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00193: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00194: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00195: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00196: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00197: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00198: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00199: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00200: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00201: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00202: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00203: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00204: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00205: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00206: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00207: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00208: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00209: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00210: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00211: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00212: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00213: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00214: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00215: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00216: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00217: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00218: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00219: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00220: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00221: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00222: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00223: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00224: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00225: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00226: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00227: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00228: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00229: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00230: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00231: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00232: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00233: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00234: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00235: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00236: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00237: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00238: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00239: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00240: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00241: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00242: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00243: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00244: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00245: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00246: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00247: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00248: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00249: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00250: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00251: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00252: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00253: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00254: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00255: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00256: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00257: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00258: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00259: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00260: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00261: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00262: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00263: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00264: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00265: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00266: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00267: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00268: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00269: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00270: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00271: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00272: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00273: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00274: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00275: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00276: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00277: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00278: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00279: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00280: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00281: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00282: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00283: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00284: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00285: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00286: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00287: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00288: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00289: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00290: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00291: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00292: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00293: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00294: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00295: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00296: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00297: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00298: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00299: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00300: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00301: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00302: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00303: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00304: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00305: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00306: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00307: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00308: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00309: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00310: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00311: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00312: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00313: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00314: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00315: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00316: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00317: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00318: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00319: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00320: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00321: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00322: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00323: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00324: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00325: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00326: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00327: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00328: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00329: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00330: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00331: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00332: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00333: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00334: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00335: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00336: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00337: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00338: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00339: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00340: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00341: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00342: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00343: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00344: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00345: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00346: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00347: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00348: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00349: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00350: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00351: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00352: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00353: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00354: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00355: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00356: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00357: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00358: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00359: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00360: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00361: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00362: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00363: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00364: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00365: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00366: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00367: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00368: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00369: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00370: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00371: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00372: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00373: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00374: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00375: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00376: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00377: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00378: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00379: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00380: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00381: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00382: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00383: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00384: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00385: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00386: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00387: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00388: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00389: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00390: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00391: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00392: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00393: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00394: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00395: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00396: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00397: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00398: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00399: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00400: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00401: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00402: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00403: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00404: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00405: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00406: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00407: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00408: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00409: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00410: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00411: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00412: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00413: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00414: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00415: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00416: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00417: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00418: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00419: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00420: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00421: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00422: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00423: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00424: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00425: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00426: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00427: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00428: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00429: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00430: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00431: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00432: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00433: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00434: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00435: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00436: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00437: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00438: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00439: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00440: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00441: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00442: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00443: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00444: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00445: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00446: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00447: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00448: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00449: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00450: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00451: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00452: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00453: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00454: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00455: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00456: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00457: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00458: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00459: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00460: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00461: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00462: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00463: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00464: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00465: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00466: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00467: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00468: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00469: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00470: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00471: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00472: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00473: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00474: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00475: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00476: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00477: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00478: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00479: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00480: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00481: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00482: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00483: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00484: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00485: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00486: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00487: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00488: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00489: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00490: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00491: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00492: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00493: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00494: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00495: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00496: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00497: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00498: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00499: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00500: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00501: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00502: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00503: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00504: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00505: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00506: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00507: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00508: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00509: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00510: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00511: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00512: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00513: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00514: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00515: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00516: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00517: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00518: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00519: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00520: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00521: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00522: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00523: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00524: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00525: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00526: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00527: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00528: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00529: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00530: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00531: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00532: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00533: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00534: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00535: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00536: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00537: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00538: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00539: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00540: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00541: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00542: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00543: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00544: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00545: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00546: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00547: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00548: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00549: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00550: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00551: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00552: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00553: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00554: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00555: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00556: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00557: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00558: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00559: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00560: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00561: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00562: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00563: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00564: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00565: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00566: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00567: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00568: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00569: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00570: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00571: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00572: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00573: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00574: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00575: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00576: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00577: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00578: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00579: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00580: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00581: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00582: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00583: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00584: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00585: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00586: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00587: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00588: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00589: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00590: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00591: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00592: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00593: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00594: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00595: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00596: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00597: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00598: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00599: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00600: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00601: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00602: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00603: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00604: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00605: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00606: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00607: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00608: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00609: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00610: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00611: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00612: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00613: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00614: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00615: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00616: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00617: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00618: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00619: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00620: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00621: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00622: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00623: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00624: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00625: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00626: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00627: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00628: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00629: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00630: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00631: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00632: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00633: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00634: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00635: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00636: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00637: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00638: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00639: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00640: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00641: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00642: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00643: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00644: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00645: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00646: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00647: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00648: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00649: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00650: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00651: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00652: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00653: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00654: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00655: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00656: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00657: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00658: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00659: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00660: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00661: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00662: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00663: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00664: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00665: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00666: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00667: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00668: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00669: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00670: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00671: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00672: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00673: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00674: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00675: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00676: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00677: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00678: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00679: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00680: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00681: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00682: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00683: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00684: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00685: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00686: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00687: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00688: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00689: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00690: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00691: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00692: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00693: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00694: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00695: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00696: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00697: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00698: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00699: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00700: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00701: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00702: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00703: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00704: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00705: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00706: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00707: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00708: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00709: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00710: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00711: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00712: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00713: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00714: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00715: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00716: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00717: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00718: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00719: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00720: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00721: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00722: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00723: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00724: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00725: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00726: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00727: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00728: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00729: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00730: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00731: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00732: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00733: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00734: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00735: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00736: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00737: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00738: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00739: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00740: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00741: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00742: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00743: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00744: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00745: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00746: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00747: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00748: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00749: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00750: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00751: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00752: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00753: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00754: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00755: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00756: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00757: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00758: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00759: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00760: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00761: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00762: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00763: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00764: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00765: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00766: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00767: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00768: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00769: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00770: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00771: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00772: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00773: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00774: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00775: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00776: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00777: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00778: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00779: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00780: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00781: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00782: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00783: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00784: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00785: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00786: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00787: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00788: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00789: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00790: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00791: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00792: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00793: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00794: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00795: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00796: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00797: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00798: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00799: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00800: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00801: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00802: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00803: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00804: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00805: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00806: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00807: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00808: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00809: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00810: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00811: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00812: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00813: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00814: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00815: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00816: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00817: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00818: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00819: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00820: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00821: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00822: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00823: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00824: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00825: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00826: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00827: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00828: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00829: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00830: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00831: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00832: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00833: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00834: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00835: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00836: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00837: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00838: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00839: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00840: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00841: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00842: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00843: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00844: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00845: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00846: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00847: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00848: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00849: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00850: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00851: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00852: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00853: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00854: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00855: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00856: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00857: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00858: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00859: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00860: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00861: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00862: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00863: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00864: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00865: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00866: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00867: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00868: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00869: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00870: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00871: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00872: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00873: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00874: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00875: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00876: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00877: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00878: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00879: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00880: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00881: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00882: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00883: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00884: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00885: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00886: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00887: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00888: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00889: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00890: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00891: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00892: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00893: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00894: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00895: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00896: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00897: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00898: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00899: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00900: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00901: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00902: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00903: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00904: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00905: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00906: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00907: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00908: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00909: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00910: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00911: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00912: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00913: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00914: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00915: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00916: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00917: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00918: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00919: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00920: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00921: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00922: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00923: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00924: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00925: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00926: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00927: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00928: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00929: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00930: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00931: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00932: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00933: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00934: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00935: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00936: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00937: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00938: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00939: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00940: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00941: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00942: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00943: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00944: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00945: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00946: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00947: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00948: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00949: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00950: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00951: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00952: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00953: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00954: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00955: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00956: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00957: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00958: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00959: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00960: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00961: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00962: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00963: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00964: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00965: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00966: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00967: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00968: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00969: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00970: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00971: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00972: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00973: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00974: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00975: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00976: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00977: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00978: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00979: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00980: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00981: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00982: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00983: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00984: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00985: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00986: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00987: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00988: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00989: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00990: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00991: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00992: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00993: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00994: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00995: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00996: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00997: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00998: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00999: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 01000: val_f1_score did not improve from 0.94689\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "history = model_c.fit(x_train, y_train_c, batch_size=batch, epochs=epochs, validation_data=(x_val, y_val_c), callbacks=[tbCallBack, checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_histo_vis(history, \"history/Coarse_cls1\")\n",
    "save_his(history, \"history/coarse_cls1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00009: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00010: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00061: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00062: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00063: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00064: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00065: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00066: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00067: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00068: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00069: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00070: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00071: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00072: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00073: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00074: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00075: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00076: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00077: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00078: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00079: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00080: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00081: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00082: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00083: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00084: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00085: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00086: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00087: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00088: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00089: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00090: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00091: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00092: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00093: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00094: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00095: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00096: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00097: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00098: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00099: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00100: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00101: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00102: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00103: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00104: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00105: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00106: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00107: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00108: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00109: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00110: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00111: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00112: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00113: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00114: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00115: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00116: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00117: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00118: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00119: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00120: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00121: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00122: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00123: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00124: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00125: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00126: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00127: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00128: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00129: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00130: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00131: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00132: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00133: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00134: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00135: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00136: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00137: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00138: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00139: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00140: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00141: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00142: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00143: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00144: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00145: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00146: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00147: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00148: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00149: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00150: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00151: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00152: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00153: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00154: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00155: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00156: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00157: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00158: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00159: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00160: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00161: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00162: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00163: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00164: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00165: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00166: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00167: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00168: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00169: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00170: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00171: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00172: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00173: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00174: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00175: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00176: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00177: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00178: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00179: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00180: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00181: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00182: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00183: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00184: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00185: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00186: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00187: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00188: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00189: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00190: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00191: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00192: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00193: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00194: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00195: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00196: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00197: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00198: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00199: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00200: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00201: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00202: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00203: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00204: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00205: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00206: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00207: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00208: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00209: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00210: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00211: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00212: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00213: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00214: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00215: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00216: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00217: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00218: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00219: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00220: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00221: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00222: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00223: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00224: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00225: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00226: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00227: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00228: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00229: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00230: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00231: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00232: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00233: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00234: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00235: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00236: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00237: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00238: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00239: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00240: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00241: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00242: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00243: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00244: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00245: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00246: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00247: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00248: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00249: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00250: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00251: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00252: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00253: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00254: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00255: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00256: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00257: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00258: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00259: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00260: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00261: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00262: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00263: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00264: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00265: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00266: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00267: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00268: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00269: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00270: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00271: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00272: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00273: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00274: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00275: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00276: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00277: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00278: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00279: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00280: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00281: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00282: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00283: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00284: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00285: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00286: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00287: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00288: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00289: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00290: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00291: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00292: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00293: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00294: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00295: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00296: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00297: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00298: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00299: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00300: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00301: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00302: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00303: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00304: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00305: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00306: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00307: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00308: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00309: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00310: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00311: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00312: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00313: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00314: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00315: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00316: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00317: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00318: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00319: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00320: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00321: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00322: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00323: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00324: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00325: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00326: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00327: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00328: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00329: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00330: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00331: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00332: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00333: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00334: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00335: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00336: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00337: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00338: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00339: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00340: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00341: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00342: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00343: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00344: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00345: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00346: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00347: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00348: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00349: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00350: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00351: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00352: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00353: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00354: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00355: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00356: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00357: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00358: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00359: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00360: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00361: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00362: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00363: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00364: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00365: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00366: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00367: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00368: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00369: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00370: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00371: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00372: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00373: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00374: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00375: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00376: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00377: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00378: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00379: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00380: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00381: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00382: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00383: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00384: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00385: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00386: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00387: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00388: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00389: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00390: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00391: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00392: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00393: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00394: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00395: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00396: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00397: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00398: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00399: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00400: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00401: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00402: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00403: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00404: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00405: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00406: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00407: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00408: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00409: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00410: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00411: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00412: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00413: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00414: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00415: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00416: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00417: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00418: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00419: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00420: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00421: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00422: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00423: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00424: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00425: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00426: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00427: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00428: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00429: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00430: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00431: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00432: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00433: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00434: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00435: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00436: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00437: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00438: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00439: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00440: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00441: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00442: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00443: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00444: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00445: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00446: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00447: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00448: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00449: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00450: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00451: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00452: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00453: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00454: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00455: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00456: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00457: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00458: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00459: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00460: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00461: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00462: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00463: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00464: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00465: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00466: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00467: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00468: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00469: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00470: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00471: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00472: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00473: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00474: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00475: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00476: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00477: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00478: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00479: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00480: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00481: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00482: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00483: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00484: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00485: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00486: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00487: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00488: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00489: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00490: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00491: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00492: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00493: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00494: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00495: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00496: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00497: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00498: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00499: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00500: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00501: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00502: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00503: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00504: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00505: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00506: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00507: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00508: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00509: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00510: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00511: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00512: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00513: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00514: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00515: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00516: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00517: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00518: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00519: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00520: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00521: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00522: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00523: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00524: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00525: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00526: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00527: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00528: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00529: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00530: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00531: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00532: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00533: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00534: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00535: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00536: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00537: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00538: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00539: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00540: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00541: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00542: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00543: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00544: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00545: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00546: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00547: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00548: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00549: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00550: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00551: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00552: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00553: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00554: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00555: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00556: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00557: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00558: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00559: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00560: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00561: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00562: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00563: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00564: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00565: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00566: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00567: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00568: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00569: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00570: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00571: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00572: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00573: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00574: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00575: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00576: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00577: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00578: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00579: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00580: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00581: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00582: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00583: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00584: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00585: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00586: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00587: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00588: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00589: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00590: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00591: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00592: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00593: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00594: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00595: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00596: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00597: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00598: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00599: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00600: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00601: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00602: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00603: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00604: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00605: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00606: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00607: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00608: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00609: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00610: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00611: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00612: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00613: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00614: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00615: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00616: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00617: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00618: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00619: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00620: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00621: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00622: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00623: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00624: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00625: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00626: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00627: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00628: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00629: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00630: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00631: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00632: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00633: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00634: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00635: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00636: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00637: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00638: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00639: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00640: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00641: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00642: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00643: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00644: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00645: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00646: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00647: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00648: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00649: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00650: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00651: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00652: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00653: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00654: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00655: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00656: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00657: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00658: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00659: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00660: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00661: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00662: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00663: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00664: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00665: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00666: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00667: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00668: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00669: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00670: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00671: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00672: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00673: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00674: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00675: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00676: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00677: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00678: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00679: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00680: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00681: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00682: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00683: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00684: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00685: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00686: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00687: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00688: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00689: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00690: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00691: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00692: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00693: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00694: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00695: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00696: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00697: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00698: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00699: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00700: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00701: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00702: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00703: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00704: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00705: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00706: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00707: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00708: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00709: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00710: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00711: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00712: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00713: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00714: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00715: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00716: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00717: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00718: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00719: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00720: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00721: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00722: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00723: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00724: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00725: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00726: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00727: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00728: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00729: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00730: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00731: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00732: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00733: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00734: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00735: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00736: val_f1_score did not improve from 0.94689\n",
      "\n",
      "Epoch 00737: val_f1_score did not improve from 0.94689\n"
     ]
    }
   ],
   "source": [
    "model_c.compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy', f1_score, precision, recall])\n",
    "epochs = 1000\n",
    "\n",
    "history = model_c.fit(x_train, y_train_c, batch_size=batch, epochs=epochs, validation_data=(x_val, y_val_c), callbacks=[tbCallBack, checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histo_vis(history, \"history/Coarse_cls2\")\n",
    "save_his(history, \"history/coarse_cls2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Fine Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Fine Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_model():\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='relu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='relu')(net)\n",
    "    net = Dropout(.2)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1152, activation='elu')(net)\n",
    "    out_fine = Dense(61, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= sgd_coarse,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', f1_score, precision, recall])\n",
    "    \n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fine Classifiers on Respective Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(y,yh):\n",
    "    # Threshold \n",
    "    yht = np.zeros(np.shape(yh))\n",
    "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "    # Evaluate Error\n",
    "    error = float(np.count_nonzero(np.count_nonzero(y-yht,1)))/len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(coarse_categories):\n",
    "\n",
    "    epochs = 500\n",
    "    \n",
    "    # Get all training data for the coarse category\n",
    "    ix = np.where([(y_train[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_tix = x_train[ix]\n",
    "    y_tix = y_train[ix]\n",
    "    \n",
    "    # Get all validation data for the coarse category\n",
    "    ix_v = np.where([(y_val[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_vix = x_val[ix_v]\n",
    "    y_vix = y_val[ix_v]\n",
    "\n",
    "    history = fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, epochs=epochs, validation_data=(x_vix, y_vix))\n",
    "\n",
    "    train_histo_vis(history, \"history/Fine_cls1\")\n",
    "    save_his(history, \"history/fine_cls1.json\")\n",
    "    \n",
    "    fine_models['models'][i].compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy', f1_score, precision, recall])\n",
    "    \n",
    "    epochs = 500\n",
    "    \n",
    "    hist = fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, epochs=epochs, validation_data=(x_vix, y_vix))\n",
    "\n",
    "    train_histo_vis(history, \"history/Fine_cls2\")\n",
    "    save_his(history, \"history/fine_cls2.json\")\n",
    "        \n",
    "    yh_f = fine_models['models'][i].predict(x_val[ix_v], batch_size=batch)\n",
    "    print('Fine Classifier '+str(i)+' Error: '+str(get_error(y_val[ix_v],yh_f))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def eval_hdcnn(X, y):\n",
    "    yh = np.zeros(np.shape(y))\n",
    "    \n",
    "    yh_s = model.predict(X, batch_size=batch)\n",
    "    \n",
    "    print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
    "    \n",
    "    yh_c = model_c.predict(X, batch_size=batch)\n",
    "    y_c = np.dot(y,fine2coarse)\n",
    "    \n",
    "    print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
    "\n",
    "    for i in range(coarse_categories):\n",
    "        if i%5 == 0:\n",
    "            print(\"Evaluating Fine Classifier: \", str(i))\n",
    "        #fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
    "        yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
    "    \n",
    "    print('Overall Error: '+str(get_error(y,yh)))\n",
    "    return yh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yh = eval_hdcnn(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_test; y = y_test\n",
    "\n",
    "yh = np.zeros(np.shape(y))\n",
    "\n",
    "yh_s = model.predict(X, batch_size=batch)\n",
    "\n",
    "print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
    "\n",
    "yh_c = model_c.predict(X, batch_size=batch)\n",
    "y_c = np.dot(y,fine2coarse)\n",
    "\n",
    "print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
    "\n",
    "for i in range(coarse_categories):\n",
    "    if i%5 == 0:\n",
    "        print(\"Evaluating Fine Classifier: \"+ str(i))\n",
    "    fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
    "    yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
    "\n",
    "print('Overall Error: '+str(get_error(y,yh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error function: Debug\n",
    "yht = np.zeros(np.shape(yh))\n",
    "yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "# Evaluate Error\n",
    "error = float(np.count_nonzero(np.count_nonzero(y-yht,1)))/len(y)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
