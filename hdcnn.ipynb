{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchically Deep Convolutional Neural Network For Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 \n",
    "\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't pre-allocate memory; allocate as-needed\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3 # Only allow a total fraction the GPU memory to be allocated\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/models/'):\n",
    "    os.mkdir('data/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of coarse categories\n",
    "coarse_categories = 20\n",
    "\n",
    "# The number of fine categories\n",
    "fine_categories = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Cifar100 Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y_c), (x_test, y_c_test) = cifar100.load_data(label_mode='coarse')\n",
    "(X, y), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-To-Coarse Mapping**\n",
    "\n",
    "(Ideally, this would be done through spectral clustering as opposed to hard-coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
    "for i in range(coarse_categories):\n",
    "    index = np.where(y_c_test[:,0] == i)[0]\n",
    "    fine_cat = np.unique([y_test[j,0] for j in index])\n",
    "    for j in fine_cat:\n",
    "        fine2coarse[j,i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = 0; # Clear y_c in interest of saving mem\n",
    "y_c_test=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: One Hot Encoding\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function extends a matrix to one-hot encoding\n",
    "#    \n",
    "#    Parameters:\n",
    "#        y    Array of label values\n",
    "# \n",
    "#    Returns:\n",
    "#        y_new    One hot encoded array of labels\n",
    "################################################################################\n",
    "def one_hot(y):\n",
    "    n_values = np.max(y) + 1\n",
    "    y_new = np.eye(n_values)[y[:,0]]\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 100)\n"
     ]
    }
   ],
   "source": [
    "y=one_hot(y)\n",
    "y_test=one_hot(y_test)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply ZCA Whitening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: ZCA\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function applies ZCA Whitening to the image set\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def zca(x_1, x_2, epsilon=1e-5):\n",
    "        \n",
    "    with tf.name_scope('ZCA'):\n",
    "        \n",
    "        x1 = tf.placeholder(tf.float64, shape=np.shape(x_1), name='placeholder_x1')\n",
    "        x2 = tf.placeholder(tf.float64, shape=np.shape(x_2), name='placeholder_x2')\n",
    "        \n",
    "        flatx = tf.cast(tf.reshape(x1, (-1, np.prod(x_1.shape[-3:])),name=\"reshape_flat\"),tf.float64,name=\"flatx\")\n",
    "        sigma = tf.tensordot(tf.transpose(flatx),flatx, 1,name=\"sigma\") / tf.cast(tf.shape(flatx)[0],tf.float64) ### N-1 or N?\n",
    "        s, u, v = tf.svd(sigma,name=\"svd\")\n",
    "        pc = tf.tensordot(tf.tensordot(u,tf.diag(1. / tf.sqrt(s+epsilon)),1,name=\"inner_dot\"),tf.transpose(u),1, name=\"pc\")\n",
    "        \n",
    "        net1 = tf.tensordot(flatx, pc,1,name=\"whiten1\")\n",
    "        net1 = tf.reshape(net1,np.shape(x_1), name=\"output1\")\n",
    "        \n",
    "        flatx2 = tf.cast(tf.reshape(x2, (-1, np.prod(x_2.shape[-3:])),name=\"reshape_flat2\"),tf.float64,name=\"flatx2\")\n",
    "        net2 = tf.tensordot(flatx2, pc,1,name=\"whiten2\")\n",
    "        net2 = tf.reshape(net2,np.shape(x_2), name=\"output2\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_1,x_2 = sess.run([net1,net2], feed_dict={x1: x_1, x2: x_2})    \n",
    "    return x_1,x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "X,x_test = zca(X,x_test)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - ZCA Whitening: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Training set into Training and Validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=.1, random_state=0)\n",
    "X = 0\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_cifar100_data(X_train, Y_train, X_valid, Y_valid, img_rows, img_cols):\n",
    "    \n",
    "    nb_train_samples = 3000 # 3000 training samples\n",
    "    nb_valid_samples = 100 # 100 validation samples\n",
    "    # Load cifar10 training and validation sets\n",
    "    # (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "#     Y_train = np_utils.to_categorical(Y_train[:], num_classes)\n",
    "#     Y_valid = np_utils.to_categorical(Y_valid[:], num_classes)\n",
    "    Y_train = Y_train[:nb_train_samples]\n",
    "    Y_valid = Y_valid[:nb_valid_samples]\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = resize_cifar100_data(x_train, y_train, x_val, y_val, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flip, pad and randomly crop each photo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: Preprocess Img\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function pads images by 4 pixels, randomly crops them, then\n",
    "#        randomly flips them\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def preprocess_img(X,y):\n",
    "        \n",
    "    with tf.name_scope('Preproc'):\n",
    "        \n",
    "        images = tf.placeholder(tf.float64, shape=np.shape(X))\n",
    "        labels = tf.placeholder(tf.float64, shape=np.shape(y))\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.flip_left_right(img), images)\n",
    "        net = tf.map_fn(lambda img: tf.image.rot90(img), net)\n",
    "        net = tf.image.resize_image_with_crop_or_pad(net,40,40)\n",
    "        net = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net)\n",
    "\n",
    "        net1 = tf.image.resize_image_with_crop_or_pad(images,40,40)\n",
    "        net1 = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net1)\n",
    "        \n",
    "        net = tf.concat([net, net1],0)\n",
    "        net = tf.random_shuffle(net, seed=0)\n",
    "        net_labels = tf.concat([labels, labels],0)\n",
    "        net_labels = tf.random_shuffle(net_labels,seed=0)\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.random_flip_up_down(img), net)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_t,y_t = sess.run([net,net_labels], feed_dict={images: X, labels: y})    \n",
    "    return x_t,y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "x_train,y_train = preprocess_img(x_train,y_train)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - Img Preprocessing: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# in_layer = Input(shape=(32, 32, 3), dtype='float32', name='main_input')\n",
    "\n",
    "# net = Conv2D(384, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(384, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(384, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.2)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(640, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.3)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(768, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.4)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(896, 3, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.5)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "# net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "# net = Dropout(.6)(net)\n",
    "# net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "# net = Flatten()(net)\n",
    "# net = Dense(1152, activation='elu')(net)\n",
    "# net = Dense(100, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_v1 import InceptionV1 \n",
    "# NiN network\n",
    "# model = Model(inputs=in_layer,outputs=net)\n",
    "# Inception v1\n",
    "in_layer, net, model = InceptionV1(weights=None,classes=100) # classes = sum of all fine classes\n",
    "sgd_coarse = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('data/models/model_coarse'+str(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training history visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_histo_vis(history):\n",
    "    # Training history visualization\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = kr.callbacks.TensorBoard(log_dir='./data/graph/elu_drop/', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 13s 4ms/step - loss: 4.5710 - acc: 0.0367 - val_loss: 6.9480 - val_acc: 0.0200\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 4.1876 - acc: 0.0683 - val_loss: 6.0416 - val_acc: 0.0300\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.9489 - acc: 0.0907 - val_loss: 4.4793 - val_acc: 0.0400\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.7080 - acc: 0.1250 - val_loss: 4.8530 - val_acc: 0.0400\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.5087 - acc: 0.1590 - val_loss: 4.6174 - val_acc: 0.0400\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.3322 - acc: 0.1873 - val_loss: 4.2110 - val_acc: 0.0900\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.1004 - acc: 0.2307 - val_loss: 4.4987 - val_acc: 0.1400\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.9627 - acc: 0.2460 - val_loss: 4.2205 - val_acc: 0.1000\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.7395 - acc: 0.2810 - val_loss: 4.4592 - val_acc: 0.1300\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.5493 - acc: 0.3250 - val_loss: 4.1561 - val_acc: 0.1300\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 11/15\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.3436 - acc: 0.3857 - val_loss: 4.2374 - val_acc: 0.1700\n",
      "Epoch 12/15\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.1194 - acc: 0.4393 - val_loss: 3.9296 - val_acc: 0.1900\n",
      "Epoch 13/15\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.8779 - acc: 0.4960 - val_loss: 4.2754 - val_acc: 0.1200\n",
      "Epoch 14/15\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.7543 - acc: 0.5257 - val_loss: 4.9343 - val_acc: 0.1600\n",
      "Epoch 15/15\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.5285 - acc: 0.5833 - val_loss: 4.5303 - val_acc: 0.1000\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 16/20\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.2794 - acc: 0.6497 - val_loss: 4.2608 - val_acc: 0.1700\n",
      "Epoch 17/20\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.1224 - acc: 0.7017 - val_loss: 4.0613 - val_acc: 0.1800\n",
      "Epoch 18/20\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.9538 - acc: 0.7473 - val_loss: 4.3445 - val_acc: 0.2000\n",
      "Epoch 19/20\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.7373 - acc: 0.8153 - val_loss: 4.2851 - val_acc: 0.1600\n",
      "Epoch 20/20\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.6287 - acc: 0.8420 - val_loss: 4.4587 - val_acc: 0.1600\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 21/25\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.5051 - acc: 0.8810 - val_loss: 4.1093 - val_acc: 0.1900\n",
      "Epoch 22/25\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.3754 - acc: 0.9177 - val_loss: 3.9598 - val_acc: 0.2100\n",
      "Epoch 23/25\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.2828 - acc: 0.9407 - val_loss: 4.1121 - val_acc: 0.2400\n",
      "Epoch 24/25\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.2998 - acc: 0.9350 - val_loss: 4.9939 - val_acc: 0.1300\n",
      "Epoch 25/25\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.2288 - acc: 0.9593 - val_loss: 3.9393 - val_acc: 0.1600\n",
      "Train on 3000 samples, validate on 100 samples\n",
      "Epoch 26/30\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.1584 - acc: 0.9760 - val_loss: 4.2493 - val_acc: 0.1800\n",
      "Epoch 27/30\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.1561 - acc: 0.9693 - val_loss: 4.3102 - val_acc: 0.2100\n",
      "Epoch 28/30\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0775 - acc: 0.9947 - val_loss: 3.7919 - val_acc: 0.2700\n",
      "Epoch 29/30\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0443 - acc: 0.9963 - val_loss: 4.3425 - val_acc: 0.1700\n",
      "Epoch 30/30\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0691 - acc: 0.9917 - val_loss: 4.3244 - val_acc: 0.2100\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "step = 5\n",
    "stop = 30\n",
    "\n",
    "while index < stop:\n",
    "    history = model.fit(x_train, y_train, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val), callbacks=[tbCallBack])\n",
    "    index += step\n",
    "    model.save_weights('data/models/model_coarse'+str(index))\n",
    "save_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_histo_vis(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_fine = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'main_input')\n",
      "(1, 'Conv2d_1a_7x7_conv')\n",
      "(2, 'Conv2d_1a_7x7_bn')\n",
      "(3, 'Conv2d_1a_7x7_act')\n",
      "(4, 'MaxPool_2a_3x3')\n",
      "(5, 'Conv2d_2b_1x1_conv')\n",
      "(6, 'Conv2d_2b_1x1_bn')\n",
      "(7, 'Conv2d_2b_1x1_act')\n",
      "(8, 'Conv2d_2c_3x3_conv')\n",
      "(9, 'Conv2d_2c_3x3_bn')\n",
      "(10, 'Conv2d_2c_3x3_act')\n",
      "(11, 'MaxPool_3a_3x3')\n",
      "(12, 'Mixed_3b_Branch_1_a_1x1_conv')\n",
      "(13, 'Mixed_3b_Branch_2_a_1x1_conv')\n",
      "(14, 'Mixed_3b_Branch_1_a_1x1_bn')\n",
      "(15, 'Mixed_3b_Branch_2_a_1x1_bn')\n",
      "(16, 'Mixed_3b_Branch_1_a_1x1_act')\n",
      "(17, 'Mixed_3b_Branch_2_a_1x1_act')\n",
      "(18, 'Mixed_3b_Branch_3_a_max')\n",
      "(19, 'Mixed_3b_Branch_0_a_1x1_conv')\n",
      "(20, 'Mixed_3b_Branch_1_b_3x3_conv')\n",
      "(21, 'Mixed_3b_Branch_2_b_3x3_conv')\n",
      "(22, 'Mixed_3b_Branch_3_b_1x1_conv')\n",
      "(23, 'Mixed_3b_Branch_0_a_1x1_bn')\n",
      "(24, 'Mixed_3b_Branch_1_b_3x3_bn')\n",
      "(25, 'Mixed_3b_Branch_2_b_3x3_bn')\n",
      "(26, 'Mixed_3b_Branch_3_b_1x1_bn')\n",
      "(27, 'Mixed_3b_Branch_0_a_1x1_act')\n",
      "(28, 'Mixed_3b_Branch_1_b_3x3_act')\n",
      "(29, 'Mixed_3b_Branch_2_b_3x3_act')\n",
      "(30, 'Mixed_3b_Branch_3_b_1x1_act')\n",
      "(31, 'Mixed_3b_Concatenated')\n",
      "(32, 'Mixed_3c_Branch_1_a_1x1_conv')\n",
      "(33, 'Mixed_3c_Branch_2_a_1x1_conv')\n",
      "(34, 'Mixed_3c_Branch_1_a_1x1_bn')\n",
      "(35, 'Mixed_3c_Branch_2_a_1x1_bn')\n",
      "(36, 'Mixed_3c_Branch_1_a_1x1_act')\n",
      "(37, 'Mixed_3c_Branch_2_a_1x1_act')\n",
      "(38, 'Mixed_3c_Branch_3_a_max')\n",
      "(39, 'Mixed_3c_Branch_0_a_1x1_conv')\n",
      "(40, 'Mixed_3c_Branch_1_b_3x3_conv')\n",
      "(41, 'Mixed_3c_Branch_2_b_3x3_conv')\n",
      "(42, 'Mixed_3c_Branch_3_b_1x1_conv')\n",
      "(43, 'Mixed_3c_Branch_0_a_1x1_bn')\n",
      "(44, 'Mixed_3c_Branch_1_b_3x3_bn')\n",
      "(45, 'Mixed_3c_Branch_2_b_3x3_bn')\n",
      "(46, 'Mixed_3c_Branch_3_b_1x1_bn')\n",
      "(47, 'Mixed_3c_Branch_0_a_1x1_act')\n",
      "(48, 'Mixed_3c_Branch_1_b_3x3_act')\n",
      "(49, 'Mixed_3c_Branch_2_b_3x3_act')\n",
      "(50, 'Mixed_3c_Branch_3_b_1x1_act')\n",
      "(51, 'Mixed_3c_Concatenated')\n",
      "(52, 'MaxPool_4a_3x3')\n",
      "(53, 'Mixed_4b_Branch_1_a_1x1_conv')\n",
      "(54, 'Mixed_4b_Branch_2_a_1x1_conv')\n",
      "(55, 'Mixed_4b_Branch_1_a_1x1_bn')\n",
      "(56, 'Mixed_4b_Branch_2_a_1x1_bn')\n",
      "(57, 'Mixed_4b_Branch_1_a_1x1_act')\n",
      "(58, 'Mixed_4b_Branch_2_a_1x1_act')\n",
      "(59, 'Mixed_4b_Branch_3_a_max')\n",
      "(60, 'Mixed_4b_Branch_0_a_1x1_conv')\n",
      "(61, 'Mixed_4b_Branch_1_b_3x3_conv')\n",
      "(62, 'Mixed_4b_Branch_2_b_3x3_conv')\n",
      "(63, 'Mixed_4b_Branch_3_b_1x1_conv')\n",
      "(64, 'Mixed_4b_Branch_0_a_1x1_bn')\n",
      "(65, 'Mixed_4b_Branch_1_b_3x3_bn')\n",
      "(66, 'Mixed_4b_Branch_2_b_3x3_bn')\n",
      "(67, 'Mixed_4b_Branch_3_b_1x1_bn')\n",
      "(68, 'Mixed_4b_Branch_0_a_1x1_act')\n",
      "(69, 'Mixed_4b_Branch_1_b_3x3_act')\n",
      "(70, 'Mixed_4b_Branch_2_b_3x3_act')\n",
      "(71, 'Mixed_4b_Branch_3_b_1x1_act')\n",
      "(72, 'Mixed_4b_Concatenated')\n",
      "(73, 'Mixed_4c_Branch_1_a_1x1_conv')\n",
      "(74, 'Mixed_4c_Branch_2_a_1x1_conv')\n",
      "(75, 'Mixed_4c_Branch_1_a_1x1_bn')\n",
      "(76, 'Mixed_4c_Branch_2_a_1x1_bn')\n",
      "(77, 'Mixed_4c_Branch_1_a_1x1_act')\n",
      "(78, 'Mixed_4c_Branch_2_a_1x1_act')\n",
      "(79, 'Mixed_4c_Branch_3_a_max')\n",
      "(80, 'Mixed_4c_Branch_0_a_1x1_conv')\n",
      "(81, 'Mixed_4c_Branch_1_b_3x3_conv')\n",
      "(82, 'Mixed_4c_Branch_2_b_3x3_conv')\n",
      "(83, 'Mixed_4c_Branch_3_b_1x1_conv')\n",
      "(84, 'Mixed_4c_Branch_0_a_1x1_bn')\n",
      "(85, 'Mixed_4c_Branch_1_b_3x3_bn')\n",
      "(86, 'Mixed_4c_Branch_2_b_3x3_bn')\n",
      "(87, 'Mixed_4c_Branch_3_b_1x1_bn')\n",
      "(88, 'Mixed_4c_Branch_0_a_1x1_act')\n",
      "(89, 'Mixed_4c_Branch_1_b_3x3_act')\n",
      "(90, 'Mixed_4c_Branch_2_b_3x3_act')\n",
      "(91, 'Mixed_4c_Branch_3_b_1x1_act')\n",
      "(92, 'Mixed_4c_Concatenated')\n",
      "(93, 'Mixed_4d_Branch_1_a_1x1_conv')\n",
      "(94, 'Mixed_4d_Branch_2_a_1x1_conv')\n",
      "(95, 'Mixed_4d_Branch_1_a_1x1_bn')\n",
      "(96, 'Mixed_4d_Branch_2_a_1x1_bn')\n",
      "(97, 'Mixed_4d_Branch_1_a_1x1_act')\n",
      "(98, 'Mixed_4d_Branch_2_a_1x1_act')\n",
      "(99, 'Mixed_4d_Branch_3_a_max')\n",
      "(100, 'Mixed_4d_Branch_0_a_1x1_conv')\n",
      "(101, 'Mixed_4d_Branch_1_b_3x3_conv')\n",
      "(102, 'Mixed_4d_Branch_2_b_3x3_conv')\n",
      "(103, 'Mixed_4d_Branch_3_b_1x1_conv')\n",
      "(104, 'Mixed_4d_Branch_0_a_1x1_bn')\n",
      "(105, 'Mixed_4d_Branch_1_b_3x3_bn')\n",
      "(106, 'Mixed_4d_Branch_2_b_3x3_bn')\n",
      "(107, 'Mixed_4d_Branch_3_b_1x1_bn')\n",
      "(108, 'Mixed_4d_Branch_0_a_1x1_act')\n",
      "(109, 'Mixed_4d_Branch_1_b_3x3_act')\n",
      "(110, 'Mixed_4d_Branch_2_b_3x3_act')\n",
      "(111, 'Mixed_4d_Branch_3_b_1x1_act')\n",
      "(112, 'Mixed_4d_Concatenated')\n",
      "(113, 'Mixed_4e_Branch_1_a_1x1_conv')\n",
      "(114, 'Mixed_4e_Branch_2_a_1x1_conv')\n",
      "(115, 'Mixed_4e_Branch_1_a_1x1_bn')\n",
      "(116, 'Mixed_4e_Branch_2_a_1x1_bn')\n",
      "(117, 'Mixed_4e_Branch_1_a_1x1_act')\n",
      "(118, 'Mixed_4e_Branch_2_a_1x1_act')\n",
      "(119, 'Mixed_4e_Branch_3_a_max')\n",
      "(120, 'Mixed_4e_Branch_0_a_1x1_conv')\n",
      "(121, 'Mixed_4e_Branch_1_b_3x3_conv')\n",
      "(122, 'Mixed_4e_Branch_2_b_3x3_conv')\n",
      "(123, 'Mixed_4e_Branch_3_b_1x1_conv')\n",
      "(124, 'Mixed_4e_Branch_0_a_1x1_bn')\n",
      "(125, 'Mixed_4e_Branch_1_b_3x3_bn')\n",
      "(126, 'Mixed_4e_Branch_2_b_3x3_bn')\n",
      "(127, 'Mixed_4e_Branch_3_b_1x1_bn')\n",
      "(128, 'Mixed_4e_Branch_0_a_1x1_act')\n",
      "(129, 'Mixed_4e_Branch_1_b_3x3_act')\n",
      "(130, 'Mixed_4e_Branch_2_b_3x3_act')\n",
      "(131, 'Mixed_4e_Branch_3_b_1x1_act')\n",
      "(132, 'Mixed_4e_Concatenated')\n",
      "(133, 'Mixed_4f_Branch_1_a_1x1_conv')\n",
      "(134, 'Mixed_4f_Branch_2_a_1x1_conv')\n",
      "(135, 'Mixed_4f_Branch_1_a_1x1_bn')\n",
      "(136, 'Mixed_4f_Branch_2_a_1x1_bn')\n",
      "(137, 'Mixed_4f_Branch_1_a_1x1_act')\n",
      "(138, 'Mixed_4f_Branch_2_a_1x1_act')\n",
      "(139, 'Mixed_4f_Branch_3_a_max')\n",
      "(140, 'Mixed_4f_Branch_0_a_1x1_conv')\n",
      "(141, 'Mixed_4f_Branch_1_b_3x3_conv')\n",
      "(142, 'Mixed_4f_Branch_2_b_3x3_conv')\n",
      "(143, 'Mixed_4f_Branch_3_b_1x1_conv')\n",
      "(144, 'Mixed_4f_Branch_0_a_1x1_bn')\n",
      "(145, 'Mixed_4f_Branch_1_b_3x3_bn')\n",
      "(146, 'Mixed_4f_Branch_2_b_3x3_bn')\n",
      "(147, 'Mixed_4f_Branch_3_b_1x1_bn')\n",
      "(148, 'Mixed_4f_Branch_0_a_1x1_act')\n",
      "(149, 'Mixed_4f_Branch_1_b_3x3_act')\n",
      "(150, 'Mixed_4f_Branch_2_b_3x3_act')\n",
      "(151, 'Mixed_4f_Branch_3_b_1x1_act')\n",
      "(152, 'Mixed_4f_Concatenated')\n",
      "(153, 'MaxPool_5a_2x2')\n",
      "(154, 'Mixed_5b_Branch_1_a_1x1_conv')\n",
      "(155, 'Mixed_5b_Branch_2_a_1x1_conv')\n",
      "(156, 'Mixed_5b_Branch_1_a_1x1_bn')\n",
      "(157, 'Mixed_5b_Branch_2_a_1x1_bn')\n",
      "(158, 'Mixed_5b_Branch_1_a_1x1_act')\n",
      "(159, 'Mixed_5b_Branch_2_a_1x1_act')\n",
      "(160, 'Mixed_5b_Branch_3_a_max')\n",
      "(161, 'Mixed_5b_Branch_0_a_1x1_conv')\n",
      "(162, 'Mixed_5b_Branch_1_b_3x3_conv')\n",
      "(163, 'Mixed_5b_Branch_2_b_3x3_conv')\n",
      "(164, 'Mixed_5b_Branch_3_b_1x1_conv')\n",
      "(165, 'Mixed_5b_Branch_0_a_1x1_bn')\n",
      "(166, 'Mixed_5b_Branch_1_b_3x3_bn')\n",
      "(167, 'Mixed_5b_Branch_2_b_3x3_bn')\n",
      "(168, 'Mixed_5b_Branch_3_b_1x1_bn')\n",
      "(169, 'Mixed_5b_Branch_0_a_1x1_act')\n",
      "(170, 'Mixed_5b_Branch_1_b_3x3_act')\n",
      "(171, 'Mixed_5b_Branch_2_b_3x3_act')\n",
      "(172, 'Mixed_5b_Branch_3_b_1x1_act')\n",
      "(173, 'Mixed_5b_Concatenated')\n",
      "(174, 'Mixed_5c_Branch_1_a_1x1_conv')\n",
      "(175, 'Mixed_5c_Branch_2_a_1x1_conv')\n",
      "(176, 'Mixed_5c_Branch_1_a_1x1_bn')\n",
      "(177, 'Mixed_5c_Branch_2_a_1x1_bn')\n",
      "(178, 'Mixed_5c_Branch_1_a_1x1_act')\n",
      "(179, 'Mixed_5c_Branch_2_a_1x1_act')\n",
      "(180, 'Mixed_5c_Branch_3_a_max')\n",
      "(181, 'Mixed_5c_Branch_0_a_1x1_conv')\n",
      "(182, 'Mixed_5c_Branch_1_b_3x3_conv')\n",
      "(183, 'Mixed_5c_Branch_2_b_3x3_conv')\n",
      "(184, 'Mixed_5c_Branch_3_b_1x1_conv')\n",
      "(185, 'Mixed_5c_Branch_0_a_1x1_bn')\n",
      "(186, 'Mixed_5c_Branch_1_b_3x3_bn')\n",
      "(187, 'Mixed_5c_Branch_2_b_3x3_bn')\n",
      "(188, 'Mixed_5c_Branch_3_b_1x1_bn')\n",
      "(189, 'Mixed_5c_Branch_0_a_1x1_act')\n",
      "(190, 'Mixed_5c_Branch_1_b_3x3_act')\n",
      "(191, 'Mixed_5c_Branch_2_b_3x3_act')\n",
      "(192, 'Mixed_5c_Branch_3_b_1x1_act')\n",
      "(193, 'Mixed_5c_Concatenated')\n",
      "(194, 'average_pooling2d_1')\n",
      "(195, 'dropout_1')\n",
      "(196, 'Logits')\n",
      "(197, 'Logits_flat')\n",
      "(198, 'Predictions')\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mixed_5c_Branch_2_b_3x3_act'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-8].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will freeze all layers\n",
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Coarse Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c = np.dot(y_train,fine2coarse)\n",
    "y_val_c = np.dot(y_val,fine2coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (1, 1, 832, 48) not compatible with provided weight shape (1, 1, 832, 192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1e121886a202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (1, 1, 832, 48) not compatible with provided weight shape (1, 1, 832, 192)"
     ]
    }
   ],
   "source": [
    "# NiN\n",
    "# net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "# Inception\n",
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-6].output)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "out_coarse = Dense(20, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model_c.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 30\n",
    "step = 10\n",
    "stop = 40\n",
    "\n",
    "while index < stop:\n",
    "    history = model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histo_vis(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c.compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "stop = 50\n",
    "\n",
    "while index < stop:\n",
    "    history = model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histo_vis(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Fine Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Fine Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_model():\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "    net = Dropout(.6)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1152, activation='elu')(net)\n",
    "    out_fine = Dense(100, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= sgd_coarse,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fine Classifiers on Respective Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(y,yh):\n",
    "    # Threshold \n",
    "    yht = np.zeros(np.shape(yh))\n",
    "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "    # Evaluate Error\n",
    "    error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(coarse_categories):\n",
    "    index= 0\n",
    "    step = 5\n",
    "    stop = 5\n",
    "    \n",
    "    # Get all training data for the coarse category\n",
    "    ix = np.where([(y_train[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_tix = x_train[ix]\n",
    "    y_tix = y_train[ix]\n",
    "    \n",
    "    # Get all validation data for the coarse category\n",
    "    ix_v = np.where([(y_val[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_vix = x_val[ix_v]\n",
    "    y_vix = y_val[ix_v]\n",
    "    \n",
    "    while index < stop:\n",
    "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
    "        index += step\n",
    "    \n",
    "    fine_models['models'][i].compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    stop = 10\n",
    "\n",
    "    while index < stop:\n",
    "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
    "        index += step\n",
    "        \n",
    "    yh_f = fine_models['models'][i].predict(x_val[ix_v], batch_size=batch)\n",
    "    print('Fine Classifier '+str(i)+' Error: '+str(get_error(y_val[ix_v],yh_f))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Probabilistic Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def eval_hdcnn(X, y):\n",
    "    yh = np.zeros(np.shape(y))\n",
    "    \n",
    "    yh_s = model.predict(X, batch_size=batch)\n",
    "    \n",
    "    print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
    "    \n",
    "    yh_c = model_c.predict(X, batch_size=batch)\n",
    "    y_c = np.dot(y,fine2coarse)\n",
    "    \n",
    "    print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
    "\n",
    "    for i in range(coarse_categories):\n",
    "        if i%5 == 0:\n",
    "            print(\"Evaluating Fine Classifier: \", str(i))\n",
    "        #fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
    "        yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
    "    \n",
    "    print('Overall Error: '+str(get_error(y,yh)))\n",
    "    return yh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yh = eval_hdcnn(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_val; y = y_val\n",
    "\n",
    "yh = np.zeros(np.shape(y))\n",
    "\n",
    "yh_s = model.predict(X, batch_size=batch)\n",
    "\n",
    "print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
    "\n",
    "yh_c = model_c.predict(X, batch_size=batch)\n",
    "y_c = np.dot(y,fine2coarse)\n",
    "\n",
    "print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
    "\n",
    "for i in range(coarse_categories):\n",
    "    if i%5 == 0:\n",
    "        print(\"Evaluating Fine Classifier: \"+ str(i))\n",
    "    fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
    "    yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
    "\n",
    "print('Overall Error: '+str(get_error(y,yh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error function: Debug\n",
    "yht = np.zeros(np.shape(yh))\n",
    "yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "# Evaluate Error\n",
    "error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
